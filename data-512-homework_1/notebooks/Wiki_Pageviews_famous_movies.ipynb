{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Wikipedia article views of famous movies\n",
    "This notebook has been used to publish datasets of monthly article traffic for a select set of movies from English Wikipedia from July 1, 2015 through September 30, 2023. It also shows some exploratory analysis in forms of visualizations.\n",
    "\n",
    "\n",
    "## Source of data\n",
    "The page view data is sourced using the [Wikimedia REST API](https://www.mediawiki.org/wiki/Wikimedia_REST_API). The API documentation, [pageviews/per-article](https://wikimedia.org/api/rest_v1/#/Pageviews%20data), covers additional details that may be helpful when trying to use or understand how to retrieve monthly page view per article.\n",
    "\n",
    "The list of articles represent 1359 Academy award winning movies.\n",
    "\n",
    "## License\n",
    "Step 1a  and Step 1b were developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - August 14, 2023\n",
    "\n",
    "\n",
    "## Implementation\n",
    "Let us deepdive into the implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These are standard python modules\n",
    "import json, time, urllib.parse\n",
    "#\n",
    "# The 'requests' module is not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
    "import requests\n",
    "\n",
    "# Standard python libaries and modules for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1a : Defining the parameters used to scrape data from the Wikipedia API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests\n",
    "API_REQUEST_PAGEVIEWS_ENDPOINT = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'\n",
    "\n",
    "# This is a parameterized string that specifies what kind of pageviews request we are going to make\n",
    "# In this case it will be a 'per-article' based request. The string is a format string so that we can\n",
    "# replace each parameter with an appropriate value before making the request\n",
    "API_REQUEST_PER_ARTICLE_PARAMS = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'\n",
    "\n",
    "# The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making a request to the Wikimedia API they ask that you include your email address which will allow them\n",
    "# to contact you if something happens - such as - your code exceeding rate limits - or some other error \n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<uwnetid@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# This is just a list of English Wikipedia article titles that we can use for example requests\n",
    "ARTICLE_TITLES = [ 'Everything Everywhere All at Once','Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "\n",
    "# This template is used to map parameter values into the API_REQUST_PER_ARTICLE_PARAMS portion of an API request. The dictionary has a\n",
    "# field/key for each of the required parameters. In the example, below, we only vary the article name, so the majority of the fields\n",
    "# can stay constant for each request. Of course, these values *could* be changed if necessary.\n",
    "ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"\",      # this should be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015010100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023090100\"    # end date\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b: Defining a function that can be reused to scrape data from the PI. The function returns pageviews per article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_pageviews_per_article(article_title = None, \n",
    "                                  access_method='desktop',\n",
    "                                  endpoint_url = API_REQUEST_PAGEVIEWS_ENDPOINT, \n",
    "                                  endpoint_params = API_REQUEST_PER_ARTICLE_PARAMS, \n",
    "                                  request_template = ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE,\n",
    "                                  headers = REQUEST_HEADERS):\n",
    "    \n",
    "    request_template['access']=access_method\n",
    "\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['article'] = article_title\n",
    "\n",
    "    if not request_template['article']:\n",
    "        raise Exception(\"Must supply an article title to make a pageviews request.\")\n",
    "\n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(request_template['article'].replace(' ','_'))\n",
    "    request_template['article'] = article_title_encoded\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1c: Loading data of Academy award winning movies from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape  (1358, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Whale (2022 film)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Academy award winning movies in a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "famous_movies_df=pd.read_csv('/Users/sayo/Documents/Projects/Repos/DATA-512/sources/thank_the_academy.AUG.2023.csv',\n",
    "                             header=0\n",
    "                             )\n",
    "print('Shape ',famous_movies_df.shape)\n",
    "famous_movies_df['name'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1d: Iterating through all movie names for getting their page views accessed via DESKTOP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_view={}\n",
    "for i in range(len(famous_movies_df)):\n",
    "    article_title=famous_movies_df['name'][i]\n",
    "    print(\"Getting pageview data for: \",article_title)\n",
    "    views = request_pageviews_per_article(article_title)\n",
    "    formatted_view[article_title]=(views['items'])\n",
    "    print(f\"Finished appending {len(views['items'])} months data to json file for: {article_title}\")\n",
    "with open('academy_monthly_desktop.json','a' ) as file:\n",
    "    json.dump(formatted_view,file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit testing that the data structure produced is of valid JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "  with open('academy_monthly_desktop.json', \"r\") as read_content: \n",
    "    json.load(read_content)\n",
    "except json.JSONDecodeError:\n",
    "  print(\"The JSON string is not valid\")\n",
    "else:\n",
    "  print(\"The JSON string is valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1e: Iterating through all movie names for getting their page views accessed via MOBILE (both mobile-app and mobile-web):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_view_mob={}\n",
    "for i in range(len(famous_movies_df)):\n",
    "    article_title_mob=famous_movies_df['name'][i]\n",
    "    print(\"Getting pageview data for: \",article_title_mob)\n",
    "    views_mob_app = request_pageviews_per_article(article_title_mob,access_method='mobile-app')\n",
    "    views_mob_web = request_pageviews_per_article(article_title_mob,access_method='mobile-web')\n",
    "    views_mob_app=views_mob_app['items']\n",
    "    views_mob_web=views_mob_web['items']\n",
    "    consolidated_page_view=[]\n",
    "    for x in range(len(views_mob_app)):\n",
    "        total_views=views_mob_app[x]['views']+views_mob_web[x]['views']\n",
    "        consolidated_page_view.append({\n",
    "                                \"project\": views_mob_app[x]['project'],\n",
    "                                \"article\": views_mob_app[x]['article'],\n",
    "                                \"granularity\": views_mob_app[x]['granularity'],\n",
    "                                \"timestamp\": views_mob_app[x]['timestamp'],\n",
    "                                \"agent\": views_mob_app[x]['agent'],\n",
    "                                \"views\": total_views\n",
    "                                })\n",
    "    formatted_view_mob[article_title_mob]=(consolidated_page_view)\n",
    "with open('academy_monthly_mobile2.json','a' ) as file:\n",
    "    json.dump(formatted_view_mob,file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit testing\n",
    "try:\n",
    "  with open('academy_monthly_mobile2.json', \"r\") as read_content: \n",
    "    json.load(read_content)\n",
    "except json.JSONDecodeError:\n",
    "  print(\"The JSON string is not valid\")\n",
    "else:\n",
    "  print(\"The JSON string is valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1f: Iterating through all movie names for getting their page views accessed via MOBILE + DESKTOP :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_view_all={}\n",
    "for i in range(len(famous_movies_df)):\n",
    "    article_title_all=famous_movies_df['name'][i]\n",
    "    print(\"Getting pageview data for: \",article_title_all)\n",
    "    views_mob_app = request_pageviews_per_article(article_title_all,access_method='mobile-app')\n",
    "    views_mob_web = request_pageviews_per_article(article_title_all,access_method='mobile-web')\n",
    "    views_mob_desktop = request_pageviews_per_article(article_title_all,access_method='desktop')\n",
    "    views_mob_app=views_mob_app['items']\n",
    "    views_mob_web=views_mob_web['items']\n",
    "    views_mob_desktop=views_mob_desktop['items']\n",
    "    consolidated_page_view=[]\n",
    "    for x in range(len(views_mob_app)):\n",
    "        total_views=views_mob_app[x]['views']+views_mob_web[x]['views']+views_mob_desktop[x]['views']\n",
    "        consolidated_page_view.append({\n",
    "                                \"project\": views_mob_app[x]['project'],\n",
    "                                \"article\": views_mob_app[x]['article'],\n",
    "                                \"granularity\": views_mob_app[x]['granularity'],\n",
    "                                \"timestamp\": views_mob_app[x]['timestamp'],\n",
    "                                \"agent\": views_mob_app[x]['agent'],\n",
    "                                \"views\": total_views\n",
    "                                })\n",
    "    formatted_view_all[article_title_all]=(consolidated_page_view)\n",
    "with open('academy_monthly_cumulative2.json','a' ) as file:\n",
    "    json.dump(formatted_view_all,file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  with open('academy_monthly_cumulative2.json', \"r\") as read_content: \n",
    "    json.load(read_content)\n",
    "except json.JSONDecodeError:\n",
    "  print(\"The JSON string is not valid\")\n",
    "else:\n",
    "  print(\"The JSON string is valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Analysis\n",
    "\n",
    "### Step 2a: Transforming JSON dataset to pandas dataframe for easier Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## convert json to pandas DF for easier EDA -DESKTOP\n",
    "with open('academy_monthly_desktop.json', \"r\") as read_content: \n",
    "    data_json=json.load(read_content)\n",
    "\n",
    "dataframes = []\n",
    "for key, value in data_json.items():\n",
    "    df = pd.DataFrame(value) \n",
    "    df['article']=key\n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "monthly_desktop_df = pd.concat(dataframes, ignore_index=True)\n",
    "monthly_desktop_df.head(-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert json to pandas DF for easier EDA -MOBILE\n",
    "\n",
    "with open('academy_monthly_mobile2.json', \"r\") as read_content2: \n",
    "    data_json_mob=json.load(read_content2)\n",
    "\n",
    "dataframes_mob = []\n",
    "for key1, value1 in data_json_mob.items():\n",
    "    df_mob = pd.DataFrame(value1) \n",
    "    df_mob['article']=key1\n",
    "    dataframes_mob.append(df_mob)\n",
    "\n",
    "\n",
    "monthly_mobile_df = pd.concat(dataframes_mob, ignore_index=True)\n",
    "monthly_mobile_df.head(-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert json to pandas DF for easier EDA - ALL(CUMULATIVE)\n",
    "\n",
    "with open('academy_monthly_cumulative2.json', \"r\") as read_content3: \n",
    "    data_json_all=json.load(read_content3)\n",
    "\n",
    "dataframes_all = []\n",
    "for key2, value2 in data_json_all.items():\n",
    "    df_all = pd.DataFrame(value2) \n",
    "    df_all['article']=key2\n",
    "    dataframes_all.append(df_all)\n",
    "\n",
    "\n",
    "monthly_all_df = pd.concat(dataframes_all, ignore_index=True)\n",
    "monthly_all_df.head(-10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Visual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Average and Minimum Average - \n",
    "The first graph  contains time series for the articles that have the highest average monthly page requests and the lowest average monthly page requests for desktop access and mobile access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "average_views = monthly_desktop_df.groupby('article')['views'].mean().reset_index()\n",
    "average_views_mob=monthly_mobile_df.groupby('article')['views'].mean().reset_index()\n",
    "\n",
    "# Sort articles based on average views for desktop\n",
    "sorted_articles = average_views.sort_values(by='views', ascending=False)\n",
    "\n",
    "# Convert 'timestamp' column to datetime objects\n",
    "monthly_desktop_df['timestamp'] = pd.to_datetime(monthly_desktop_df['timestamp'], format='%Y%m%d%H')\n",
    "monthly_mobile_df['timestamp'] = pd.to_datetime(monthly_mobile_df['timestamp'], format='%Y%m%d%H')\n",
    "\n",
    "# Sort articles based on average views for mobile\n",
    "sorted_articles_mob = average_views_mob.sort_values(by='views', ascending=False)\n",
    "\n",
    "# Select articles with highest and lowest average views for desktop\n",
    "articles_highest_avg = sorted_articles.head(1)['article'].values[0]\n",
    "articles_lowest_avg = sorted_articles.tail(1)['article'].values[0]\n",
    "\n",
    "# Select articles with highest and lowest average views for desktop\n",
    "articles_highest_avg_mob = sorted_articles_mob.head(1)['article'].values[0]\n",
    "articles_lowest_avg_mob = sorted_articles_mob.tail(1)['article'].values[0]\n",
    "\n",
    "# Filter DataFrame for selected articles for desktop\n",
    "highest_avg_df = monthly_desktop_df[monthly_desktop_df['article'] == articles_highest_avg]\n",
    "lowest_avg_df = monthly_desktop_df[monthly_desktop_df['article'] == articles_lowest_avg]\n",
    "\n",
    "# Filter DataFrame for selected articles for desktop\n",
    "highest_avg_df_mob = monthly_mobile_df[monthly_mobile_df['article'] == articles_highest_avg_mob]\n",
    "lowest_avg_df_mob = monthly_mobile_df[monthly_mobile_df['article'] == articles_lowest_avg_mob]\n",
    "\n",
    "# Plot time series data for articles with highest and lowest average views\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "\n",
    "#plot desktop high /low\n",
    "plt.plot(sorted(highest_avg_df['timestamp']), highest_avg_df['views'], label=f'Highest Avg for Desktop: {articles_highest_avg}')\n",
    "plt.plot(sorted(lowest_avg_df['timestamp']), lowest_avg_df['views'], label=f'Lowest Avg for Desktop: {articles_lowest_avg}')\n",
    "#plot mobile high/low\n",
    "plt.plot(sorted(highest_avg_df_mob['timestamp']), highest_avg_df_mob['views'], label=f'Highest Avg for Mobile: {articles_highest_avg_mob}')\n",
    "plt.plot(sorted(lowest_avg_df_mob['timestamp']), lowest_avg_df_mob['views'], label=f'Lowest Avg for Mobile: {articles_lowest_avg_mob}')\n",
    "\n",
    "half_year_locator = mdates.MonthLocator(interval=6)\n",
    "year_month_formatter = mdates.DateFormatter(\"%Y-%m\") # four digits for year, two for month\n",
    "\n",
    "ax.xaxis.set_major_locator(half_year_locator)\n",
    "ax.xaxis.set_major_formatter(year_month_formatter) # formatter for major axis only\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Page Requests')\n",
    "plt.title('Page Requests Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.ticklabel_format(axis='y', style='plain')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 Peak Page Views - \n",
    "The second graph should contain time series for the top 10 article pages by largest (peak) page views over the entire time by access type. You first find the month for each article that contains the highest (peak) page views, and then order the articles by these peak values. Your graph should contain the top 10 for desktop and top 10 for mobile access (20 lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total page views for each article\n",
    "total_views_desktop = monthly_desktop_df.groupby('article')['views'].sum().reset_index()\n",
    "total_views_mobile= monthly_mobile_df.groupby('article')['views'].sum().reset_index()\n",
    "\n",
    "# Sort articles based on total views and select the top 10\n",
    "top_10_articles_desktop = total_views_desktop.sort_values(by='views', ascending=False).head(10)\n",
    "top_10_articles_mobile = total_views_mobile.sort_values(by='views', ascending=False).head(10)\n",
    "\n",
    "# Filter DataFrame for top 10 articles\n",
    "top_10_df_desktop = monthly_desktop_df[monthly_desktop_df['article'].isin(top_10_articles_desktop['article'])]\n",
    "top_10_df_mobile = monthly_mobile_df[monthly_mobile_df['article'].isin(top_10_articles_desktop['article'])]\n",
    "\n",
    "# Plot time series data for top 10 articles\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "\n",
    "for article in top_10_articles_desktop['article']:\n",
    "    article_data = top_10_df_desktop[top_10_df_desktop['article'] == article]\n",
    "    plt.plot(article_data['timestamp'], article_data['views'],'o-', label='Desktop: '+article)\n",
    "\n",
    "for article in top_10_articles_mobile['article']:\n",
    "    article_data_mobile = top_10_df_mobile[top_10_df_mobile['article'] == article]\n",
    "    plt.plot(article_data_mobile['timestamp'], article_data_mobile['views'],'o-', label='Mobile: '+article)\n",
    "\n",
    "half_year_locator = mdates.MonthLocator(interval=6)\n",
    "year_month_formatter = mdates.DateFormatter(\"%Y-%m\") # four digits for year, two for month\n",
    "\n",
    "ax.xaxis.set_major_locator(half_year_locator)\n",
    "ax.xaxis.set_major_formatter(year_month_formatter) # formatter for major axis only\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Page Requests')\n",
    "plt.title('Top 10 Articles by Page Views Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.ticklabel_format(axis='y', style='plain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fewest Months of Data - \n",
    "\n",
    "The third graph should show pages that have the fewest months of available data. These will all be relatively short time series and should contain a set of the most recent academy award winners. Your graph should show the 10 articles with the fewest months of data for desktop access and the 10 articles with the fewest months of data for mobile access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_available_desktop = monthly_desktop_df.groupby('article')['timestamp'].nunique().reset_index()\n",
    "\n",
    "least_available_10articles_desktop=total_data_available_desktop.sort_values(by='timestamp',ascending=True).head(10)\n",
    "\n",
    "least_10_df_desktop = monthly_desktop_df[monthly_desktop_df['article'].isin(least_available_10articles_desktop['article'])]\n",
    "\n",
    "# Plot time series data for 10 articles with least available data for desktop \n",
    "fig2,ax2=plt.subplots(figsize=(20, 10))\n",
    "\n",
    "for article in least_available_10articles_desktop['article']:\n",
    "    article_data_least = least_10_df_desktop[least_10_df_desktop['article'] == article]\n",
    "    plt.plot(article_data_least['timestamp'], article_data_least['views'],label=article)\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Page Views')\n",
    "plt.title('Least 10 Articles by Available data Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.ticklabel_format(axis='y', style='plain')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data598",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
